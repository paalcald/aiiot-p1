{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "Importamos las librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import reduce\n",
        "from scipy import sparse\n",
        "from surprise import Dataset, Reader, accuracy, SVD, NMF\n",
        "from surprise.model_selection import train_test_split\n",
        "import surprise.prediction_algorithms.knns as knns\n",
        "import surprise.prediction_algorithms.matrix_factorization\n",
        "from sklearn.metrics import ndcg_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Importamos los datos del dataset de manera manual para disponer de movies.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We load all the variables we care about\n",
        "ratings= pd.read_csv(\"ml-100k/ratings.csv\")\n",
        "movies = pd.read_csv('ml-100k/movies.csv')\n",
        "tags = pd.read_csv('ml-100k/tags.csv')\n",
        "links = pd.read_csv('ml-100k/links.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos la forma de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         4.0\n",
              "1         4.0\n",
              "2         4.0\n",
              "3         5.0\n",
              "4         5.0\n",
              "         ... \n",
              "100831    4.0\n",
              "100832    5.0\n",
              "100833    5.0\n",
              "100834    5.0\n",
              "100835    3.0\n",
              "Name: rating, Length: 100836, dtype: float64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings['rating']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que tenemos:\n",
        "- userId: ID del usuario que dejó la calificación\n",
        "- movieId: ID de la pelicula calificada\n",
        "- rating: Calificación de 1 a 5 \n",
        "- timestamp: Unidad de tiempo en la que se dejó la clasificación\n",
        "\n",
        "Convertimos los datos para la libreria Surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "reader = Reader(rating_scale=(1,5))\n",
        "# Train/Test split using pandas alone\n",
        "#train = ratings.sample(frac=0.75, random_state=1234)\n",
        "#test = ratings.drop(train.index)\n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Separamos los conjuntos de train y test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainset, testset = train_test_split(data, test_size=0.25, random_state=1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Realizamos las predicciones con diferentes algoritmos\n",
        "\n",
        "Obtenemos predicciones con KNNBasic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        }
      ],
      "source": [
        "knn = knns.KNNBasic(sim_options={\"name\": \"pearson\"})\n",
        "knn.fit(trainset)\n",
        "knn_pred = knn.test(testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con KNNBasic basado en productos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        }
      ],
      "source": [
        "knn_prod = knns.KNNBasic(sim_options={\"name\": \"pearson\", 'user_based': False})\n",
        "knn_prod.fit(trainset)\n",
        "knn_prod_pred = knn_prod.test(testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con SVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "svd = SVD()\n",
        "svd.fit(trainset)\n",
        "svd_predictions = svd.test(testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con NMF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "nmf = NMF()\n",
        "nmf.fit(trainset)\n",
        "nmf_predictions = svd.test(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = {\"KNNSBasic User Based\": knn_pred, \"KNNSBasic Product Based\": knn_prod_pred, \"SVD\": svd_predictions, \"NMF\": nmf_predictions}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Funcion auxiliar para obtener los resultados de las predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_titles(prediction, n, movies):\n",
        "    return [movies.loc[movies['movieId'] == recomended_id, 'title'].item() for recomended_id in [item.iid for item in prediction[0:n]]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Obtenemos las predicciones para cada algoritmo\n",
        "KNNSBasic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (281762232.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[33], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    get_titles(knn_pred, 5ls, movies)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ],
      "source": [
        "get_titles(knn_pred, 5ls, movies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "KNNSBasic products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Rogue One: A Star Wars Story (2016)',\n",
              " 'Godfather: Part II, The (1974)',\n",
              " 'Breakfast Club, The (1985)',\n",
              " 'Apollo 13 (1995)',\n",
              " 'Office Space (1999)',\n",
              " 'Logan (2017)',\n",
              " 'Tucker & Dale vs Evil (2010)',\n",
              " 'Easy Rider (1969)',\n",
              " 'Purge, The (2013)',\n",
              " 'Guardians of the Galaxy (2014)']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_titles(knn_prod_pred, 5, movies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Rogue One: A Star Wars Story (2016)',\n",
              " 'Godfather: Part II, The (1974)',\n",
              " 'Breakfast Club, The (1985)',\n",
              " 'Apollo 13 (1995)',\n",
              " 'Office Space (1999)',\n",
              " 'Logan (2017)',\n",
              " 'Tucker & Dale vs Evil (2010)',\n",
              " 'Easy Rider (1969)',\n",
              " 'Purge, The (2013)',\n",
              " 'Guardians of the Galaxy (2014)',\n",
              " 'Dreamers, The (2003)',\n",
              " 'Congo (1995)',\n",
              " 'Talented Mr. Ripley, The (1999)',\n",
              " 'Scanner Darkly, A (2006)',\n",
              " 'Get Shorty (1995)',\n",
              " 'Twelve Monkeys (a.k.a. 12 Monkeys) (1995)',\n",
              " 'Dogtown and Z-Boyz (2001)',\n",
              " 'Fight Club (1999)',\n",
              " 'Hard Candy (2005)',\n",
              " 'Bruce Almighty (2003)',\n",
              " 'Chamber, The (1996)',\n",
              " 'American President, The (1995)',\n",
              " 'Mission: Impossible (1996)',\n",
              " 'Forrest Gump (1994)',\n",
              " 'Taxi 4 (2007)',\n",
              " 'Snowpiercer (2013)',\n",
              " 'Truman Show, The (1998)',\n",
              " 'Desperately Seeking Susan (1985)',\n",
              " 'Twister (1996)',\n",
              " 'Beauty and the Beast (1991)']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_titles(svd_predictions, 5, movies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NMF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Rogue One: A Star Wars Story (2016)',\n",
              " 'Godfather: Part II, The (1974)',\n",
              " 'Breakfast Club, The (1985)',\n",
              " 'Apollo 13 (1995)',\n",
              " 'Office Space (1999)',\n",
              " 'Logan (2017)',\n",
              " 'Tucker & Dale vs Evil (2010)',\n",
              " 'Easy Rider (1969)',\n",
              " 'Purge, The (2013)',\n",
              " 'Guardians of the Galaxy (2014)']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_titles(nmf_predictions, 5, movies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Generamos la tabla de métricas\n",
        "Función auxiliar para generar el diccionario de usuarios y predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def groupby_id(d, p):\n",
        "    if p.uid in d:\n",
        "        d[p.uid].append(p)\n",
        "        return d\n",
        "    else:\n",
        "        d[p.uid] = [p]\n",
        "        return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generamos nuestra lista de recomendaciones y la ordenamos por positivas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_recomendation_list(predictions):\n",
        "    recomendation_list = reduce(groupby_id, predictions, {})\n",
        "    for recomendations in recomendation_list.values():\n",
        "        recomendations.sort(key=lambda x: x.est, reverse=True)\n",
        "    return recomendation_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recallAtK(rec_list, k = 10):\n",
        "    out = {}\n",
        "    for user, user_preds in rec_list.items():\n",
        "        relevant_k = len(list(filter(lambda p: p.r_ui >= 4 and p.est >=4, user_preds[:k])))\n",
        "        n_rel = len(list(filter(lambda p: p.r_ui >= 4, user_preds)))\n",
        "        if len(user_preds) >= k:\n",
        "            out[user] = relevant_k / n_rel if n_rel != 0 else 0\n",
        "    return out\n",
        "\n",
        "def precisionAtK(rec_list, k = 10):\n",
        "    out = {}\n",
        "    for user, user_preds in rec_list.items():\n",
        "        relevant_k = len(list(filter(lambda p: p.r_ui >= 4 and p.est >=4, user_preds[:k])))\n",
        "        n_rec_k = len(list(filter(lambda p: p.est >= 4, user_preds[:k])))\n",
        "        if len(user_preds) >= k:\n",
        "            out[user] = relevant_k / n_rec_k if n_rec_k != 0 else 0\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "#No entiendo NDCG esto está sacado de github issues para surprise\n",
        "def get_ndcg(surprise_predictions, k_highest_scores=None):\n",
        "    uids = [int(p.uid) for p in surprise_predictions ]\n",
        "    iids = [int(p.iid) for p in surprise_predictions ]\n",
        "    r_uis = [p.r_ui for p in surprise_predictions ]\n",
        "    ests = [p.est for p in surprise_predictions ]\n",
        "    \n",
        "    assert(len(uids) == len(iids) == len(r_uis) == len(ests) )    \n",
        "    \n",
        "    sparse_preds = sparse.coo_matrix( (ests, (uids , iids )) )\n",
        "    sparse_vals = sparse.coo_matrix( (r_uis, (uids , iids )) )\n",
        "    \n",
        "    dense_preds = sparse_preds.toarray()\n",
        "    dense_vals = sparse_vals.toarray()\n",
        "    \n",
        "    return ndcg_score(y_true= dense_vals , y_score= dense_preds, k=k_highest_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculamos accuracy, Recall y precision @ 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.9772\n",
            "RMSE: 0.9678\n"
          ]
        }
      ],
      "source": [
        "metricas_evaluacion = {\"Accuracy\": [], \"Recall@k\": [], \"Precision@k\": [], \"NDGC\": []}\n",
        "for pred in predictions.values():\n",
        "    metricas_evaluacion[\"Accuracy\"].append(accuracy.rmse(pred))\n",
        "    recs = get_recomendation_list(pred)\n",
        "    recalls = recallAtK(recs)\n",
        "    avg_recall = sum(recalls.values()) / len(recalls)\n",
        "    metricas_evaluacion[\"Recall@k\"].append(avg_recall)\n",
        "    precision = precisionAtK(recs)\n",
        "    avg_precision = sum(precision.values()) / len(recalls)\n",
        "    metricas_evaluacion[\"Precision@k\"].append(avg_precision)\n",
        "    ndgc = get_ndcg(pred)\n",
        "    metricas_evaluacion[\"NDGC\"].append(ndgc)\n",
        "metricas = pd.DataFrame(data=metricas_evaluacion, index=predictions.keys())\n",
        "metricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Conclusion\n",
        "\n",
        "Parece ser que en todas las métricas el que mejor funciona para este dataset es KNNSBasic basado en usuarios.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "iaiot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
